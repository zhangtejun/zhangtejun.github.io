---
layout: post
title:  "kafka"
date:   2017-07-01 10:29:00
author: zhangtejun
categories: zhangtejun
---
##### kafka
高吞吐量分布式消息系统。
kafka是linkedin用于日志处理的分布式消息队列，同时支持离线和在线日志处理。
Kafka对消息保存时根据topic进行归类，发送消息者为producer,消息接收者为consumer，kafka集群由多个Kafka实例组成，每个实例（server）称为
broker。他们都依赖于zookeeper来保证系统的可用性，为集群保存一项meta信息。

实时性处理。

##### JMS
JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，
用于在两个应用程序之间，或分布式系统中发送消息，进行`异步通信`。Java消息服务是一个与具体平台无关的API，绝大多数MOM
提供商都对JMS提供支持。

jMS消息模型
* queue: 队列，P2P(点对点)
* topic: publish - subscribe发布订阅

kafka没有队列概念，引入了Group。

##### kafka安装
* Step 1: Download the code

Download the 0.11.0.0 release and un-tar it.

```shell
> tar -xzf kafka_2.11-0.11.0.0.tgz
> cd kafka_2.11-0.11.0.0
```
* Step 2: Start the server

```shell
nohup bin/kafka-server-start.sh config/server.properties > kafka.log 2>&1 &

#jps 类似ps -ef
```

##### nohup
使用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响他的运行
，注意了nohup没有后台运行的意思；&才是后台运行。

&是指在后台运行，但当用户推出(挂起)的时候，命令自动也跟着退出

nohup COMMAND &
这样就能使命令永久的在后台执行

##### topic
```shell
#1.创建topic
bin/kafka-topics.sh --zookeeper  zookeeperServerName/localhost:端口  --create --topic test  --replication-factor(重复为2即备份) 2 --partitions(分区为2) 2

#2.查看topics
bin/kafka-topics.sh --zookeeper  zookeeperServerName:端口 --list 

#3.查看topic test
bin/kafka-topics.sh --zookeeper  zookeeperServerName:端口 --describe --topic test
```

##### 启动消费者
```shell
./bin/kafka-console-consumer.sh --zookeeper  zookeeperServerName:端口  --topic test
```
##### 启动生产者
```shell
./bin/kafka-console-producer.sh --broker-list kafkaServerName:端口 --topic test
```


##### Kafka应用场景
1. 日志收集

日志收集方面，其实开源产品有很多，包括 Scribe、Apache Flume。很多人使用 Kafka 代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或 HDFS）进行处理。然而 Kafka忽略掉文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让 Kafka 处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的系统比如 Scribe 或者 Flume 来说，Kafka 提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。

2. 行为跟踪

Kafka 的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的 topic 里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到 Hadoop 离线数据仓库里处理。

3. 持久性日志（commit log）

Kafka 可以为一种外部的持久性日志的分布式系统提供服务。这种日志可以在节点间备份数据，并为故障节点数据回复提供一种重新同步的机制。Kafka 中日志压缩功能为这种用法提供了条件。在这种用法中，Kafka 类似于 Apache BookKeeper 项目。

##### Kafka基本概念
Topic：特指 Kafka 处理的消息源（feeds of messages）的不同分类。

Partition：Topic 物理上的分组，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的 id（offset）。

Message：消息，是通信的基本单位，每个 producer 可以向一个 topic（主题）发布一些消息。

Producers：消息和数据生产者，向 Kafka 的一个 topic 发布消息的过程叫做 producers。

Consumers：消息和数据消费者，订阅 topics 并处理其发布的消息的过程叫做 consumers。

Broker：缓存代理，Kafka 集群中的一台或多台服务器统称为 broker。

##### 设计原理

Kafka 的设计初衷是希望作为一个统一的信息收集平台，能够实时的收集反馈信息，并需要能够支撑较大的数据量，且具备良好的容错能力。

1. Kafka 的 Topics/Log

一个Topic 可以认为是一类消息，每个 topic 将被分成多 partition (区),每个partition在存储层面是 append log 文件。任何发布到此 partition 的消息都会被直接追加到 log 文件的尾部，每条消息在文件中的位置称 offset（偏移量），partition 是以文件的形式存储在文件系统中。Logs 文件根据 broker 中的配置要求,保留一定时间后删除来释放磁盘空间。

Partition：

Topic 物理上的分组，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。 partition 中的每条消息都会被分配一个有序的 id（offset）。

##### Kafka的储存策略
1. kafka以 topic 来进行消息管理，每个 topic 包含多个 partition，每个 part 对应一个逻辑 log，有多个 segment 组成。

2. 每个 segment 中存储多条消息（见下图），消息 id 由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。

3. broker 收到发布消息往对应 partition 的最后一个 segment 上添加该消息。

4. 每个 part 在内存中对应一个index，记录每个 segment 中的第一条消息偏移。

5. 发布者发到某个 topic 的 消息会被均匀的分布到多个 part 上（随机或根据用户指定的回调函数进行分布），broker 收到发布消息往对应 part 的最后一个 segment 上添加 该消息，当某个 segment 上的消息条数达到配置值或消息发布时间超过阈值时，segment 上的消息会被 flush 到磁盘，只有 flush 到磁盘上的消息订阅者才能订阅到，segment 达到一定的大小后将不会再往该 segment 写数据，broker 会创建新的 segment。


##### Kafka的消息发送的流程

由于 kafka broker 会持久化数据，broker 没有内存压力，因此，consumer 非常适合采取 pull 的方式消费数据 Producer 向 Kafka（push）推数据，consumer 从 kafka 拉（pull）数据。

##### Kafka 的 Zookeeper 协调控制

1. 管理 broker 与 consumer 的动态加入与离开。
2. 触发负载均衡，当 broker 或 consumer 加入或离开时会触发负载均衡算法，使得一个 consumer group 内的多个 consumer 的订阅负载平衡。
3. 维护消费关系及每个 partion 的消费信息。
4. Zookeeper上的细节：
	1. 每个 broker 启动后会在 zookeeper 上注册一个临时的 broker registry，包含 broker 的 ip 地址和端口号，所存储的 topics 和 partitions 信息。

    2. 每个 consumer 启动后会在 zookeeper 上注册一个临时的 consumer registry：包含 consumer 所属的consumer group 以及订阅的 topics。

	3. 每个 consumer group 关 联一个临时的 owner regi




##### 单节点broker 

* 启动ZooKeeper
```shell
cd /usr/ZooKeeper/bin
./zkServer.sh start
 #bin/zkServer.sh stop 停止
```

* 启动kafka服务器
```shell
root@zhtjun: cd /home/kafka/kafka_2.11-0.11.0.0
root@zhtjun: bin/kafka-server-start.sh config/server.properties > kafka.log 2>&1 &

# 创建topic
root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic tesr13
Created topic "tesr13".
# 查看topic
root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0# bin/kafka-topics.sh --list --zookeeper localhost:2181
tesr13

root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0# bin/kafka-topics.sh  --zookeeper localhost:2181   --describe --topic tesr13
Topic:tesr13    PartitionCount:1        ReplicationFactor:1     Configs:
        Topic: tesr13   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
```


##### 启动producer
```shell

root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic tesr13


```
##### 启动consumer
```shell
root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0#  bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic tesr13 --from-beginning
```
启动问题：vi config/server.properties设置listeners=PLAINTEXT://localhost:9092

java.net.UnknownHostException: zhtjun: zhtjun: Name or service not known`

在配置 /etc/hosts 127.0.0.1 zhtjun(主机名)，

##### 单节点多broker 
以上只是启动单个broker，现在启动由3个组成的集群。

* 为每个节点编写配置文件
	```shell
	root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0/config# cp server.properties server-1.properties
	root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0/config# cp server.properties server-2.properties
	
	# 修改配置 因为在同一机器上，需要指定不同的端口和日志文件
	broker.id=1
	listeners=PLAINTEXT://localhost:9093
	log.dirs=/tmp/kafka-logs-1
	broker.id=2
	listeners=PLAINTEXT://localhost:9094
	log.dirs=/tmp/kafka-logs-2
	
	```
* 启动另2个节点
```shell
bin/kafka-server-start.sh config/server-1.properties > kafka.log-1 2>&1 &

bin/kafka-server-start.sh config/server-2.properties > kafka.log-2 2>&1 &
```

创建一个有3个副本的topic
```shell
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic testfor3
root@zhtjun:/home/kafka/kafka_2.11-0.11.0.0# bin/kafka-topics.sh  --zookeeper localhost:2181   --describe --topic testfor3
Topic:testfor3  PartitionCount:1        ReplicationFactor:3     Configs:
        Topic: testfor3 Partition: 0    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2
```
Leader：负责处理消息的读写，Leader从所有节点中随机选择。

Replicas：列出所有副本节点，不管结点是否在服务中。

Isr：正在服务的节点。

##### 多节点broker
vi zoo.cfg

server.X=A:B:C 
其中X是一个数字, 表示这是第几号server. 
A是该server所在的IP地址. 
B配置该server和集群中的leader交换消息所使用的端口. 
C配置选举leader时所使用的端口. 
由于配置的是伪集群模式, 所以各个server的B, C参数必须不同.








